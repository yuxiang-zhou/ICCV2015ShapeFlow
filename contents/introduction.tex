Building and training deformable models of objects (e.g. faces, ears, bodies, bottles, vehicles etc.) has recently been widely researched for object detection, part localisation, fitting, recognition and tracking using manual annotated data. Shapes and appearances of majority of objects vary significantly from object instance. To illustrate, ears have complicated inner structures (e.g. helix, crus antihelicis, scapha, tragus, lobe etc.) which differs remarkably between ears and highly sensitive to intensity changes. Recently, we have witnessed a great
progress in object detection, alignment and recognition. 

To train deformable models with satisfiable generalisation, large amount of careful manual annotation is required. However, landmark annotation is extremely time consuming, work intensive and, most importantly, number of landmarks have to stay consistent for all training data while it is challenging to maintain the consistency or to avoid bias when annotating objects that having reach features. In ears, for example, large amount of landmarks required as the inner structure of ears are complex. To annotate an ear with clear contour, helix and cavum conchae, more than 50 landmarks are required. The inconsistency of ear features enhanced the difficulty of accurate annotation (e.g. Fossa Triangularies and Crus Helicis are optional feature of an ear also their visibility is highly sensitive to pose and illumination variation).
To illustrate how much time consuming careful ear annotation is, according to our experience, a trained annotator may need an average of (TODO: experiment) minutes per image for the manual annotation of 55 landmarks. This means that the annotation of 1000 images requires a total of about (TODO: experiment). Furthermore, personal issue, prior knowledge and circumstances can heavily bias the annotation accuracy thus second round correction might desired.

We propose framework to handle training data with inconsistent annotation, build dense shape model and introduce effective curve annotation methods. In our experiment, we show building dense models trained with inconsistent annotation and trained with curve annotation improves performance of discriminative models trained on carefully annotated data.

Uses Introductions from Nondas' paper "Automatic Construction of Deformable Models In-The-Wild" as place holder.

In this paper, we deal with the problem of automatically
constructing a robust deformable model using (1) a simple
bounding box object detector and (2) a shape by means of
a Point Distribution Model (PDM). The detector can be as
simple as the Viola-Jones object detector \cite{?}
3 which returns
only a bounding box of a detected object. Such detectors
are widely employed in commercial products (e.g.
even the cheapest digital camera has a robust face detector).
Other detectors that can be used are efficient subwindow
search \cite{?}. The
annotations that are needed to train the object detector can
be acquired very quickly, since only a bounding box containing the object is required. Specifically, after selecting
the images that are going to be used, the annotation procedure
takes a couple of seconds per image. The statistical
shape model can be created by using only 40-50 shape examples,
which can be produced by either drawing possible
shape variations of the 2D shape of the object or projecting
3D CAD model instances of the object on the 2D camera
plane (such an example is shown in \cite{?} for cars). Even
the annotation of the shape examples is not a time consuming
task, due to their small number. Furthermore, there are
unsupervised techniques to learn the shape prior (model) directly
from images \cite{?}.

Due to the fact that manual annotation is a rather costly
and labour-intensive procedure, unsupervised and semisupervised
learning of models for the tasks of alignment,
landmark localization, tracking and recognition has attracted
considerable attention \cite{?}. In this paper, we
propose a method to automatically construct deformable
models for object alignment and the most related works
are \cite{?}. The related family of techniques,
known as image-congealing \cite{?}, uses implicit
models to align a set of images as a whole, which means
that both performing alignment to a new image and constructing
a model is not straightforward. Our methodology
differs from these works because we employ an explicit texture
model which is learned through the process.

The two most closely related works to the proposed
method are the automatic construction of Active Appearance
Models (AAMs) in \cite{?} and the so-called RASL
methodology in \cite{?} for person-specific face alignment.
There are two main differences between our framework
and \cite{?}. (1) We use a predefined statistical shape model
instead of trying to find both the shape and appearance models.
We believe that with the current available optimization
techniques, it is extremely difficult to simultaneously optimize
for both the texture and shape parameters. (2) We
employ the robust component analysis of \cite{?} for the appearance
which deals with outliers. Thus, even though
our method is similar in concept to \cite{?}, these two differences
make the problem feasible to solve. In particular, the
methodology in \cite{?} fails to create a generic model even in
controlled recording conditions, due to extremely high dimensionality
of the parameters to be found and to the sensitivity
of the subspace method to outliers. This was probably
one of the reasons why the authors demonstrate very
limited and only person-specific experiments. Furthermore,
our methodology bypasses some of the limitations of \cite{?},
which requires the presence of only one low-rank subspace,
hence it has been shown to work only for the case of congealing
images of a single person. Finally, we argue that
in order for an automatically constructed AAM methodology
to be robust to both within-class and out-of-class outliers4,
which cannot be avoided in totally unsupervised settings,
statistical component analysis techniques should be
employed \cite{?}. We summarize our contributions as follows:


We present experimental results on the task of face alignment.
We choose this application because there exist many
in-the-wild facial databases with a large number of images
and annotated landmarks, hence solid quantitative evaluations
can be performed.

\clearpage